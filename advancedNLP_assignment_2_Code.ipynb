{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxS1sByMcBBJ",
        "outputId": "cb0e312d-0997-49c9-a960-ad4546029c58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# 관련 라이브러리 불러오기\n",
        "import pandas as pd\n",
        "import os\n",
        "import math\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 파일경로를 찾고 변수 file_path에 저장\n",
        "file_path = '/content/gdrive/MyDrive/nlp/Corpus/Input_Data'\n",
        "\n",
        "label_list = os.listdir(file_path)"
      ],
      "metadata": {
        "id": "nY0V4Yux4Hg-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## input data 파일명 긁어오기\n",
        "txt_list = []\n",
        "for label in label_list:\n",
        "    temp_list = os.listdir(file_path + '/' + label)\n",
        "    temp_list = [file for file in temp_list if file.endswith(\".txt\")]\n",
        "    txt_list.append(temp_list)"
      ],
      "metadata": {
        "id": "nefu-MIv4NnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 총 문서의 수\n",
        "total_doc = 0\n",
        "for text in txt_list:\n",
        "    total_doc += len(text)"
      ],
      "metadata": {
        "id": "keHZ8FDw4QpM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##빈도가 높은 형태소 5000개 확인을 위한 딕셔너리\n",
        "pos_dic = {}\n",
        "\n",
        "##문서당 명사류인 형태소 저장\n",
        "text_nn = []\n",
        "\n",
        "##문서당 형태소 수\n",
        "text_len = []\n",
        "\n",
        "##몇개의 문서에서 해당 형태소가 등장했는지 확인 위한 딕셔너리\n",
        "idf_dic = {}\n",
        "\n",
        "##test에서 쓰기 위함\n",
        "IDF = []"
      ],
      "metadata": {
        "id": "Jy-IQjlt4U3n"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(label_list)):\n",
        "    ##label 별로 문서 관리 위함\n",
        "    text_nn.append([])\n",
        "    text_len.append([])\n",
        "    for j in range(len(txt_list[i])):\n",
        "        temp = pd.read_csv(file_path + '/' + label_list[i] + '/' + txt_list[i][j], sep=\"\\t\", encoding=\"utf8\", names=['word', 'pos'])\n",
        "        ## TF 구할준비\n",
        "        nn_pos = []\n",
        "        temp_len = 0\n",
        "        ##\"여가부/NNG+,/SP\"와 같이 품사 태깅된 내용 가져\n",
        "        for pos_list in temp['pos']:\n",
        "            ##nan 같이 빈 공백 줄이 포함된 경우 처리 위함\n",
        "            if type(pos_list) == str:\n",
        "                ## '+'로 이뤄진 규칙이 있어 \"여가부/NNG\", \",/SP\"로 나눔\n",
        "                for pos in pos_list.split('+'):\n",
        "                    ## '/'로 이뤄진 규칙이 있어 \"여가부\", \"NNG\"로 나눔\n",
        "                    for item in pos.split('/'):\n",
        "                        temp_len += 1\n",
        "                        ## 명사류 형태소\n",
        "                        if 'NNG' in item:\n",
        "                            ## 딕셔너리에 있는지 확인하고 count\n",
        "                            try:\n",
        "                                pos_dic[pos] += 1\n",
        "                            except:\n",
        "                                pos_dic[pos] = 1\n",
        "                            nn_pos.append(pos)\n",
        "                        ## 명사류 형태소\n",
        "                        elif 'NNP' in item:\n",
        "                            ## 딕셔너리에 있는지 확인하고 count\n",
        "                            try:\n",
        "                                pos_dic[pos] += 1\n",
        "                            except:\n",
        "                                pos_dic[pos] = 1\n",
        "                            nn_pos.append(pos)\n",
        "        text_nn[i].append(nn_pos)\n",
        "        text_len[i].append(temp_len)\n",
        "\n",
        "        ## IDF 구할 준비 완료\n",
        "        for idf in list(set(nn_pos)):\n",
        "            try:\n",
        "                idf_dic[idf] +=1\n",
        "            except:\n",
        "                idf_dic[idf] = 1\n",
        "\n",
        "sorted_dict = dict(sorted(pos_dic.items(), key=lambda item: item[1], reverse=True))\n",
        "top_5000 = dict(list(sorted_dict.items())[:5000])\n",
        "\n",
        "file_name = sum(txt_list, [])\n",
        "train_df = pd.DataFrame(index=[file_name], columns=[list(top_5000.keys())])\n",
        "train_df = train_df.reset_index()\n",
        "train_df[\"label\"] = 99\n",
        "\n",
        "for pos in top_5000.keys():\n",
        "    IDF.append(math.log(total_doc / idf_dic[pos]))\n",
        "\n",
        "num = 0\n",
        "for i in range(len(train_df)):\n",
        "    if label_list[num] in train_df.loc[i]['level_0']:\n",
        "        train_df.loc[i, 'label'] = num\n",
        "    else:\n",
        "        num +=1\n",
        "        train_df.loc[i, 'label'] = num\n",
        "\n",
        "chk = 0\n",
        "for i in range(len(text_nn)):\n",
        "    for j in range(len(text_nn[i])):\n",
        "        for nn in list(set(text_nn[i][j])):\n",
        "            if nn in list(top_5000.keys()):\n",
        "                cnt = text_nn[i][j].count(nn)\n",
        "                TF = cnt / text_len[i][j]\n",
        "                p_chk = list(top_5000.keys()).index(nn)\n",
        "                train_df.loc[chk, nn] = TF * IDF[p_chk]\n",
        "        chk += 1\n",
        "\n",
        "train_df = train_df.fillna(0)\n",
        "\n",
        "folder_path = '/content/gdrive/MyDrive/nlp/202340211_Dohyoungkim/Input_Data/'\n",
        "for index, row in train_df.iterrows():\n",
        "    # 각 행의 첫 번째 feature를 파일명으로 사용\n",
        "    file_name = row['level_0']\n",
        "    label = row['label']\n",
        "\n",
        "    # 파일로 저장 (탭으로 열 구분)\n",
        "    file_path = f'{folder_path}' + label_list[label] + '/' + f'{file_name}'\n",
        "    with open(file_path, 'w', encoding='utf-8') as file:\n",
        "        file.write('\\t'.join(map(str, row[1:].tolist())))\n",
        "\n",
        "file_path = '/content/gdrive/MyDrive/nlp/202340211_Dohyoungkim/all_train_features.txt'\n",
        "train_df.iloc[:, 1:].to_csv(file_path, sep='\\t', index=False, header=False, line_terminator='\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qarTsy3y4XxO",
        "outputId": "ea4242ae-ecfc-4ead-d0d0-6fe210872b2b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-80d6d8134a3d>:80: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
            "  train_df.iloc[:, 1:].to_csv(file_path, sep='\\t', index=False, header=False, line_terminator='\\n')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Test data 만들기\n",
        "file_path = '/content/gdrive/MyDrive/nlp/Corpus/Test_Data'\n",
        "\n",
        "label_list = os.listdir(file_path)\n",
        "\n",
        "txt_list = [] ## input data 파일명 긁어오기\n",
        "for label in label_list:\n",
        "    temp_list = os.listdir(file_path + '/' + label)\n",
        "    temp_list = [file for file in temp_list if file.endswith(\".txt\")]\n",
        "    txt_list.append(temp_list)\n",
        "\n",
        "file_name = sum(txt_list, [])\n",
        "test_df = pd.DataFrame(index=[file_name], columns=[list(top_5000.keys())])\n",
        "test_df = test_df.reset_index()\n",
        "test_df[\"label\"] = 99\n",
        "\n",
        "num = 0\n",
        "for i in range(len(test_df)):\n",
        "    if label_list[num] in test_df.loc[i]['level_0']:\n",
        "        test_df.loc[i, 'label'] = num\n",
        "    else:\n",
        "        num +=1\n",
        "        test_df.loc[i, 'label'] = num\n",
        "\n",
        "text_nn = [] ##문서당 명사류인 형태소 저장\n",
        "text_len = [] ##문서당 형태소 수\n",
        "for i in range(len(label_list)):\n",
        "    text_nn.append([]) ##label 별로 문서 관리 위함\n",
        "    text_len.append([])\n",
        "    for j in range(len(txt_list[i])):\n",
        "        temp = pd.read_csv(file_path + '/' + label_list[i] + '/' + txt_list[i][j], sep=\"\\t\", encoding=\"utf8\", names=['word', 'pos'])\n",
        "        ## TF 구할준비\n",
        "        nn_pos = []\n",
        "        temp_len = 0\n",
        "        for pos_list in temp['pos']: ##\"여가부/NNG+,/SP\"와 같이 품사 태깅된 내용 가져\n",
        "            if type(pos_list) == str: ##nan 같이 빈 공백 줄이 포함된 경우 처리 위함\n",
        "                for pos in pos_list.split('+'): ## '+'로 이뤄진 규칙이 있어 \"여가부/NNG\", \",/SP\"로 나눔\n",
        "                    for item in pos.split('/'): ## '/'로 이뤄진 규칙이 있어 \"여가부\", \"NNG\"로 나눔\n",
        "                        temp_len += 1\n",
        "                        if 'NNG' in item: ## 명사류 형태소\n",
        "                            nn_pos.append(pos)\n",
        "                        elif 'NNP' in item: ## 명사류 형태소\n",
        "                            nn_pos.append(pos)\n",
        "        text_nn[i].append(nn_pos)\n",
        "        text_len[i].append(temp_len)\n",
        "\n",
        "chk = 0\n",
        "for i in range(len(text_nn)):\n",
        "    for j in range(len(text_nn[i])):\n",
        "        for nn in list(set(text_nn[i][j])):\n",
        "            if nn in list(top_5000.keys()):\n",
        "                cnt = text_nn[i][j].count(nn)\n",
        "                TF = cnt / text_len[i][j]\n",
        "                p_chk = list(top_5000.keys()).index(nn)\n",
        "                test_df.loc[chk, nn] = TF * IDF[p_chk]\n",
        "        chk += 1\n",
        "\n",
        "test_df = test_df.fillna(0)"
      ],
      "metadata": {
        "id": "L7wSvdtP4goj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/gdrive/MyDrive/nlp/202340211_Dohyoungkim/Test_Data/'\n",
        "for index, row in test_df.iterrows():\n",
        "    # 각 행의 첫 번째 feature를 파일명으로 사용\n",
        "    file_name = row['level_0']\n",
        "    label = row['label']\n",
        "\n",
        "    # 파일로 저장 (탭으로 열 구분)\n",
        "    file_path = f'{folder_path}' + label_list[label] + '/' + f'{file_name}'\n",
        "    with open(file_path, 'w', encoding='utf-8') as file:\n",
        "        file.write('\\t'.join(map(str, row[1:].tolist())))\n",
        "\n",
        "file_path = '/content/gdrive/MyDrive/nlp/202340211_Dohyoungkim/all_test_features.txt'\n",
        "test_df.iloc[:, 1:].to_csv(file_path, sep='\\t', index=False, header=False, line_terminator='\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUpG7nuV4jg6",
        "outputId": "9c3bda04-e8c0-46a2-c0e8-c7a1a8c44778"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-5aa0f35e27d6>:13: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
            "  test_df.iloc[:, 1:].to_csv(file_path, sep='\\t', index=False, header=False, line_terminator='\\n')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM 학습\n",
        "X_train = train_df.iloc[:, 1:-1]  # 첫 번째 feature와 마지막 feature를 제외한 feature\n",
        "y_train = train_df['label']\n",
        "\n",
        "X_test = test_df.iloc[:, 1:-1]\n",
        "y_test = test_df['label']"
      ],
      "metadata": {
        "id": "MZEYlT2q4lcC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM 모델 학습\n",
        "svm_model = svm.SVC(kernel='sigmoid', decision_function_shape='ovr', random_state=42)\n",
        "print(svm_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRcXsV_n4oFL",
        "outputId": "626e1a7d-5852-4a72-d882-fa96135a7b41"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVC(kernel='sigmoid', random_state=42)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svm_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "Ng8CrZDfEZ4M",
        "outputId": "c2b5164b-0aa8-49a4-ef52-d45f48d07b6a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(kernel='sigmoid', random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;sigmoid&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;sigmoid&#x27;, random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 데이터 예측\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "# F1 스코어 계산 및 출력\n",
        "f1 = f1_score(y_test, y_pred, average='micro')\n",
        "print(f'F1 Score(micro): {f1}')\n",
        "\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "print(f'F1 Score(macro): {f1}')\n",
        "\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "print(f'F1 Score(weighted): {f1}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGGNiWUQ4pvK",
        "outputId": "f7c98a23-6afd-4d59-f3b9-b827006f913c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score(micro): 0.7299999999999999\n",
            "F1 Score(macro): 0.7318519777045036\n",
            "F1 Score(weighted): 0.7310484155151148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 혼동 행렬 계산 및 출력\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print('Confusion Matrix:')\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYUF78GB4rOD",
        "outputId": "c5a2131e-cf07-41f7-d35a-332261cb9a6e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[14  1  0  0  0  0  0  0  0]\n",
            " [ 1 13  0  0  1  0  0  0  0]\n",
            " [ 1  2  3  0  4  0  0  0  0]\n",
            " [ 4  0  0  6  0  0  0  0  0]\n",
            " [ 1  2  3  0  4  0  0  0  0]\n",
            " [ 2  0  0  0  0  8  0  0  0]\n",
            " [ 1  0  0  0  0  0  9  0  0]\n",
            " [ 1  1  0  0  0  0  0  8  0]\n",
            " [ 1  0  0  0  1  0  0  0  8]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}